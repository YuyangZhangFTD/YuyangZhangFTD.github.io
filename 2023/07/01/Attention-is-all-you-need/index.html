<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Deep Learning,NLP," />





  <link rel="alternate" href="/atom.xml" title="Arvin's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="摘要  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder">
<meta property="og:type" content="article">
<meta property="og:title" content="Attention is all you need">
<meta property="og:url" content="http://yoursite.com/2023/07/01/Attention-is-all-you-need/index.html">
<meta property="og:site_name" content="Arvin&#39;s Blog">
<meta property="og:description" content="摘要  The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder">
<meta property="og:locale">
<meta property="og:image" content="http://yoursite.com/2023/07/01/Attention-is-all-you-need/transfomer%20-%20transoformer_model_architecture.png">
<meta property="og:image" content="http://yoursite.com/2023/07/01/Attention-is-all-you-need/transfomer%20-%20attention.png">
<meta property="og:image" content="http://yoursite.com/2023/07/01/Attention-is-all-you-need/transfomer%20-%20why_self_attention.png">
<meta property="article:published_time" content="2023-07-01T10:24:02.000Z">
<meta property="article:modified_time" content="2023-07-01T10:28:22.547Z">
<meta property="article:author" content="YuyangZhangFTD">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2023/07/01/Attention-is-all-you-need/transfomer%20-%20transoformer_model_architecture.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":true,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2023/07/01/Attention-is-all-you-need/"/>





  <title>Attention is all you need | Arvin's Blog</title>
  














<meta name="generator" content="Hexo 5.4.2"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Arvin's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Poem & Algorithm</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/07/01/Attention-is-all-you-need/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Arvin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Attention is all you need</h1>
        

        <div class="post-meta">
          

          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-07-01T18:24:02+08:00">
                2023-07-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/PaperNote/" itemprop="url" rel="index">
                    <span itemprop="name">PaperNote</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="摘要">摘要</h1>
<blockquote>
<p>The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.</p>
</blockquote>
<p>主流的序列翻译模型是基于包含encoder和decoder的RNN或者CNN模型，目前效果最好的模型是通过attention机制来连接encoder和decoder。</p>
<p>我们提出一种简洁的网络结构，Transformer，只采用attention机制，并不需要RNN和CNN的结构，在两个机器翻译的任务上的实验表明，这种模型能产生更高质量的结果，同时拥有更高的并行度，训练时间更短。</p>
<p>我们的模型在WMT 2014英语德语翻译任务上达到28.4 BLEU ，超出了所有已知模型的效果，包括集成模型，超出2 BLEU，在WMT 2014英语法语翻译任务上，单个模型的评估中，达到41.0 BLUE，而这只需要8GPU上3.5天的训练时间，是之前最好模型所需训练时间的很小一部分。</p>
<h1 id="背景">背景</h1>
<p>有很多工作将RNN、LSTM、GRN等模型应用于序列建模和语言模型建模、机器翻译等场景上，并取得了较好的结果，然而RNN这类方法在训练中会需要按照序列中元素的先后顺序，处理输入和输出，这就导致无法进行并行计算而增加训练成本。虽然已经有一些工作针对这个问题在做优化，但是序列计算的基本约束仍然存在。</p>
<p>Attention机制在众多序列建模的任务上都有较好的表现，其可以建模序列中不同部分的关系，同时并不受序列长度的影响，但在大部分工作中，Attention机制都是和RNN一起使用的。</p>
<p>本文提出一种Transformer的结构，只保留Attention机制，计算时的并行度显著提升，并且最终效果也更好。</p>
<h1 id="方法">方法</h1>
<p>再序列翻译模型中一般采用Encoder-Decoder架构，Encoder将输入<span class="math inline">\((x_1, \cdots, x_n)\)</span>映射为中间表征<span class="math inline">\((z_1, \cdots, z_n)\)</span>，Decoder再将中间表征转化为<span class="math inline">\((y_1, \cdots, y_m)\)</span>，在每一步中，模型都采用一种自回归（auto-regressive）的方式，将前一个输出和中间表征共同作为Decoder的输入。</p>
<p>模型结构如下图所示，主要分为几部分，我们一一来讲。</p>
<figure>
<img src="./transfomer%20-%20transoformer_model_architecture.png" alt="transfomer - transoformer_model_architecture" /><figcaption aria-hidden="true">transfomer - transoformer_model_architecture</figcaption>
</figure>
<h2 id="encoder和decoder">Encoder和Decoder</h2>
<p>上图中左侧部分是Encoder，右侧部分是Decoder。</p>
<p>Encoder是由N=6个子部分堆叠组成，每部分包含一个Multi-Head Attention和FFN（也就是一个MLP层）组成，前后会按照ResNet的方式做输出的相加，并做LayerNorm。因为其中会有残差相加的方式，所以为了方便，所有层的输出都是一样的<span class="math inline">\(d_\text{model} = 512\)</span>。</p>
<p>Decoder也是由N=6个子部分堆叠组成，与Encoder不同的是，Decoder中间会多一层，用于引入Encoder的输出。</p>
<p>此处多提一句LayerNorm，BatchNorm大家应该都很熟悉，是针对一个Batch内每一维度的特征，做Batch内的归一化，但这种做法对于序列的处理并不一定合适，一是因为序列的长度是动态可变的，二是针对Embedding的某个维度做不同样本间的归一化没有意义，所以在语言模型中常见的做法是做LayerNorm，可以近似理解为针对某条样本，对其序列中所有Embedding做归一化。</p>
<h2 id="attention">Attention</h2>
<p>Attention函数是一种将<strong>Q</strong>uery（Q）和一个<strong>K</strong>ey-<strong>V</strong>alue（K-V）集合映射到输出的函数，输出的结果是一个值的加权和，权重由Q和K得到，值为V。</p>
<p>如图中所示，Transformer包含三种不同的Attention：</p>
<ul>
<li>图中A1，Encoder中的Multi-Head Attention，实现为Self Multi-Head Attention，Q、K、V都是输入的序列</li>
<li>图中A2，Decoder中的Masked Multi-Head Attention，实现为Self Multi-Head Attention，Q、K、V都是之前每一步输出结果的Embedding，但是会对序列右侧的元素做Mask</li>
<li>图中A3，Decoder中的Multi-Head Attention，Q为之前的输出的结果，过完Masked Multi-Head Attention的输出，K、V为Encoder的输出</li>
</ul>
<p>下面详细讲一下Attention的设计</p>
<figure>
<img src="./transfomer%20-%20attention.png" alt="transfomer - attention" /><figcaption aria-hidden="true">transfomer - attention</figcaption>
</figure>
<h3 id="scaled-dot-product-attention">Scaled Dot-Product Attention</h3>
<p>我们将上图中左侧的Attention设计称为Scaled Dot-Product Attention，其计算方式为 <span class="math display">\[
\text{Attention}(Q,K,V) = \text{softmax}\Big(\frac{QK^\intercal}{\sqrt{d_k}}\Big)\cdot V
\]</span> 先将Q和K做乘法，得到距离度量的标量，然后为了降低表征向量维度大小的影响，做scaling（维度过高时候，会导致softmax中的值过大，迭代中梯度过小）</p>
<p>中间存在一个可选的Mask的步骤，如果是Decoder中的Attention，在自回归的方式下，需要屏蔽掉句子当前预测词后面的词汇，具体的实现方式是用一个较小负数（-1e10）替换掉对应位置元素值，这样做softmax时，其取值会趋向于0，不破坏softmax求和为1的性质。</p>
<h3 id="multi-head-attention">Multi-Head Attention</h3>
<p>因为点乘的Attention并没有可学习的参数，信息量仍是由原始的QKV提供，所以相比于使用一组QKV做Attention，作者发现对QKV做不同的权重的线性映射，会有更好的效果。</p>
<p>如上图中右侧图所示，针对QKV分别作h次线性映射，投影至<span class="math inline">\(d_k,d_k,d_v\)</span>维，然后再经过多个Attention，最终将不同Attention的输出拼在一起作为最后的输出。 <span class="math display">\[
\begin{aligned}
\text{MultiHead}(Q,K,V)&amp;=\text{Concat}(\text{head}_1,\cdots,\text{head}_h) W^O \\
\text{head}_i &amp;= \text{Attention}(QW_i^Q, KW_i^K, VW_i^V) &amp;\forall i
\end{aligned}
\]</span> 其中<span class="math inline">\(W_i^Q\in\mathbb{R}^{d_\text{model}\times d_k}, W_i^K\in\mathbb{R}^{d_\text{model}\times d_k}, W_i^V\in\mathbb{R}^{d_\text{model}\times d_v},W^O\in\mathbb{R}^{h d_v\times d_\text{model}}\)</span>，本文中<span class="math inline">\(h=8,d_k=d_v=d_\text{model}/h=64\)</span>。</p>
<p>这种做法可以使的模型在不同的Head上有不同的Attention权重，同时关注到序列中多个位置。</p>
<h3 id="position-wise-feed-forward-network">Position-Wise Feed-Forward Network</h3>
<p>即前向网络，就是一个多层的全连接层 <span class="math display">\[
\text{FFN}(x)=\max(0, xW_1 +b_1) W_2 +b_2
\]</span> 激活函数为ReLU，中间层会采用更宽的网络<span class="math inline">\(d_{ff}=2048\)</span>，输出仍保持<span class="math inline">\(d_\text{model}=512\)</span>。</p>
<p>这个网络是每个位置的词都需要过的，所以叫Point-Wise，比如一个batch内的训练样本是<span class="math inline">\(B\times S\times E\)</span>，其中<span class="math inline">\(B\)</span>是batch size，一个batch内样本数，<span class="math inline">\(S\)</span>是序列长度，一条样本中的token数，<span class="math inline">\(E\)</span>是Embedding的大小，此处是每个Embedding会过这个网络。</p>
<h2 id="embedding-and-softmax">Embedding and Softmax</h2>
<p>将输入和输出都转为embedding，再过模型，embedding层是共享的，且会在原始权重基础上乘以<span class="math inline">\(\sqrt{d_\text{model}}\)</span>，在最终输出结果前，会先过一次线性映射，再过softmax。</p>
<h2 id="position-encoding">Position Encoding</h2>
<p>由于模型没有采用RNN或者CNN的结构，只用Attention无法提取到序列中元素的位置信息，所以文中采用位置编码的方式，和输出的embedding相加作为模型的输入。</p>
<p>Position Embeding也是<span class="math inline">\(d_\text{model}\)</span>大小，具体编码规则如下 <span class="math display">\[
\begin{aligned}
PE(\text{pos}, 2i)&amp;= \sin(\text{pos} / 10000^{2i / d_\text{model}}) 
\\
PE(\text{pos}, 2i+1)&amp;= \cos(\text{pos} / 10000^{2i / d_\text{model}}) 
\end{aligned}
\]</span> 其中<span class="math inline">\(\text{pos}\)</span>就是token位置，<span class="math inline">\(i\)</span>是embedding的第<span class="math inline">\(i\)</span>维。文中也提到实验对比了学习position embedding的效果，并没有明显差别，同时这种方式相比学习的embedding，序列过长的时候，外推泛化能力更强。</p>
<h2 id="why-self-attention">Why Self Attention</h2>
<p>相比于CNN和RNN，Self Attention的方式在计算量上，并没有明显差异，但是对于序列处理所需要的时间（下图中Sequential Operations，RNN需要对序列一个个元素进行处理）、以及序列前后信息传递的效率（下图中Maximum Path Length，序列上第一个元素信息传递给最后一个元素，RNN需要O(n)，CNN需要O(logk(n))）上，却更高效。</p>
<figure>
<img src="./transfomer%20-%20why_self_attention.png" alt="transfomer - why_self_attention.png" /><figcaption aria-hidden="true">transfomer - why_self_attention.png</figcaption>
</figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
            <a href="/tags/NLP/" rel="tag"># NLP</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/10/07/On-the-Factory-Floor-ML-Engineering-for-Industrial-Scale-Ads-Recommendation-Models/" rel="next" title="On the Factory Floor: ML Engineering for Industrial-Scale Ads Recommendation Models">
                <i class="fa fa-chevron-left"></i> On the Factory Floor: ML Engineering for Industrial-Scale Ads Recommendation Models
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2023/07/02/Fresh-Content-Needs-More-Attention-Multi-funnel-Fresh-Content-Recommendation/" rel="prev" title="Fresh Content Needs More Attention- Multi-funnel Fresh Content Recommendation">
                Fresh Content Needs More Attention- Multi-funnel Fresh Content Recommendation <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="uyan_frame"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/avatar.jpg"
               alt="" />
          <p class="site-author-name" itemprop="name"></p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">114</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">56</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%83%8C%E6%99%AF"><span class="nav-number">2.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#encoder%E5%92%8Cdecoder"><span class="nav-number">3.1.</span> <span class="nav-text">Encoder和Decoder</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#attention"><span class="nav-number">3.2.</span> <span class="nav-text">Attention</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#scaled-dot-product-attention"><span class="nav-number">3.2.1.</span> <span class="nav-text">Scaled Dot-Product Attention</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#multi-head-attention"><span class="nav-number">3.2.2.</span> <span class="nav-text">Multi-Head Attention</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#position-wise-feed-forward-network"><span class="nav-number">3.2.3.</span> <span class="nav-text">Position-Wise Feed-Forward Network</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#embedding-and-softmax"><span class="nav-number">3.3.</span> <span class="nav-text">Embedding and Softmax</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#position-encoding"><span class="nav-number">3.4.</span> <span class="nav-text">Position Encoding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#why-self-attention"><span class="nav-number">3.5.</span> <span class="nav-text">Why Self Attention</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">YuyangZhangFTD</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" target="_blank" rel="noopener" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  
    

    
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2140861"></script>
      <!-- UY END -->
    
  





  






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.2"></script>



  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
